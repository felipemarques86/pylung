{
    "trial_id": "3",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 100,
    "epochs": 10,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Zulu Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.30756479501724243,
        0.18962639570236206
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.30596697330474854,
            0.30725762248039246,
            0.30725759267807007,
            0.30725768208503723,
            0.30725762248039246,
            0.30725765228271484,
            0.3072575628757477,
            0.30725768208503723,
            0.30725759267807007,
            0.3072577118873596
        ],
        "bounding_box_intersection_over_union_tf": [
            0.19133810698986053,
            0.19017133116722107,
            0.19017142057418823,
            0.19017142057418823,
            0.19017142057418823,
            0.19017146527767181,
            0.19017146527767181,
            0.19017137587070465,
            0.19017140567302704,
            0.19017137587070465
        ],
        "val_loss": [
            0.30756473541259766,
            0.30756473541259766,
            0.30756473541259766,
            0.30756473541259766,
            0.30756473541259766,
            0.30756473541259766,
            0.30756473541259766,
            0.30756473541259766,
            0.30756473541259766,
            0.30756473541259766
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.18962639570236206,
            0.18962639570236206,
            0.18962639570236206,
            0.18962639570236206,
            0.18962639570236206,
            0.18962639570236206,
            0.18962639570236206,
            0.18962639570236206,
            0.18962639570236206,
            0.18962639570236206
        ]
    },
    "learning_params": {
        "learning_rate": 0.031641567861746316,
        "projection_dim": 94,
        "num_heads": 2,
        "drop_out_1": 0.013567193512031683,
        "drop_out_2": 0.0842208916997905,
        "drop_out_3": 0.01865200178844158,
        "transformer_layers": 5,
        "patch_size": 16,
        "activation": "softmax",
        "weight": 1.6949320540995028e-08,
        "momentum": 4.939343830089661e-07,
        "optimizer": "Adam"
    }
}

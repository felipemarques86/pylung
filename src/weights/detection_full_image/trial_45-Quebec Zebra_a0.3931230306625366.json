{
    "trial_id": "45",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.10726926475763321,
        0.3931230306625366
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.11697747558355331,
            0.11049821227788925,
            0.10968119651079178,
            0.10929257422685623,
            0.10896553844213486
        ],
        "bounding_box_intersection_over_union_tf": [
            0.38078346848487854,
            0.3944607079029083,
            0.3948558568954468,
            0.39597126841545105,
            0.39616185426712036
        ],
        "val_loss": [
            0.10869760811328888,
            0.1078881248831749,
            0.10718542337417603,
            0.10676899552345276,
            0.1072692945599556
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.393594354391098,
            0.39220860600471497,
            0.4021300673484802,
            0.401913046836853,
            0.39312294125556946
        ]
    },
    "learning_params": {
        "learning_rate": 6.0893509962872564e-05,
        "projection_dim": 124,
        "num_heads": 6,
        "drop_out_1": 0.06890336919068207,
        "drop_out_2": 0.049314926827452504,
        "drop_out_3": 0.02331288711301771,
        "transformer_layers": 4,
        "patch_size": 16,
        "activation": "softmax",
        "weight": 0.0005401256460456904,
        "momentum": 2.063030652833374e-05,
        "optimizer": "AdamW"
    }
}

{
    "trial_id": "37",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.11049826443195343,
        0.38764309883117676
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.12834037840366364,
            0.11860675364732742,
            0.11580546945333481,
            0.11452177911996841,
            0.11386020481586456
        ],
        "bounding_box_intersection_over_union_tf": [
            0.3529772460460663,
            0.37461206316947937,
            0.38041433691978455,
            0.38390758633613586,
            0.3856901526451111
        ],
        "val_loss": [
            0.11005924642086029,
            0.11106749624013901,
            0.11091878265142441,
            0.110728919506073,
            0.11049824208021164
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.39789411425590515,
            0.38951820135116577,
            0.3882265090942383,
            0.3876638114452362,
            0.38764309883117676
        ]
    },
    "learning_params": {
        "learning_rate": 1.5329136574425928e-07,
        "projection_dim": 128,
        "num_heads": 2,
        "drop_out_1": 0.09908636985282068,
        "drop_out_2": 0.2984210589948778,
        "drop_out_3": 0.1884765753707054,
        "transformer_layers": 3,
        "patch_size": 16,
        "activation": "softmax",
        "weight": 4.064516432687857e-05,
        "momentum": 8.02383619293943e-08,
        "optimizer": "AdamW"
    }
}

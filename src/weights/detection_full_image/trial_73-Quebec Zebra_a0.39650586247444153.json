{
    "trial_id": "73",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.10889771580696106,
        0.39650586247444153
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.28362777829170227,
            0.2922356426715851,
            0.23844340443611145,
            0.11096902936697006,
            0.11084254831075668
        ],
        "bounding_box_intersection_over_union_tf": [
            0.023808620870113373,
            0.00042634582496248186,
            0.1195027083158493,
            0.3930310904979706,
            0.3945472240447998
        ],
        "val_loss": [
            0.28943249583244324,
            0.28943249583244324,
            0.1098005548119545,
            0.10888446122407913,
            0.10889770090579987
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.0,
            0.0,
            0.3886888027191162,
            0.3967045247554779,
            0.39650580286979675
        ]
    },
    "learning_params": {
        "learning_rate": 0.0027246771411847223,
        "projection_dim": 84,
        "num_heads": 2,
        "drop_out_1": 0.1744521953091278,
        "drop_out_2": 0.08029681603190703,
        "drop_out_3": 0.08991709118740997,
        "transformer_layers": 6,
        "patch_size": 64,
        "activation": "softmax",
        "weight": 5.568515081427943e-08,
        "momentum": 1.988613821057551e-07,
        "optimizer": "AdamW"
    }
}

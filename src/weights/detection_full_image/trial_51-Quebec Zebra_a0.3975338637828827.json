{
    "trial_id": "51",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.10588691383600235,
        0.3975338637828827
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.11135266721248627,
            0.10944417864084244,
            0.10873008519411087,
            0.10836050659418106,
            0.10840053856372833
        ],
        "bounding_box_intersection_over_union_tf": [
            0.3928636908531189,
            0.3961232006549835,
            0.3971855044364929,
            0.39777642488479614,
            0.39708518981933594
        ],
        "val_loss": [
            0.10745029896497726,
            0.10695867985486984,
            0.10643648356199265,
            0.10753273218870163,
            0.10588689148426056
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.40048351883888245,
            0.39674112200737,
            0.3992340564727783,
            0.3891371786594391,
            0.3975338935852051
        ]
    },
    "learning_params": {
        "learning_rate": 2.9132255096769668e-05,
        "projection_dim": 128,
        "num_heads": 2,
        "drop_out_1": 0.0844482264709092,
        "drop_out_2": 0.23067961473718362,
        "drop_out_3": 0.028332673317440243,
        "transformer_layers": 5,
        "patch_size": 32,
        "activation": "softmax",
        "weight": 3.510801066585608e-07,
        "momentum": 1.898107003181537e-08,
        "optimizer": "AdamW"
    }
}

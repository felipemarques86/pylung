{
    "trial_id": "84",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.10732116550207138,
        0.3967544138431549
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.11307404190301895,
            0.11052560061216354,
            0.11020082980394363,
            0.10981615632772446,
            0.10959059745073318
        ],
        "bounding_box_intersection_over_union_tf": [
            0.3884254992008209,
            0.3942907154560089,
            0.3947145938873291,
            0.3949124217033386,
            0.3953912854194641
        ],
        "val_loss": [
            0.10853835195302963,
            0.10818871855735779,
            0.10790431499481201,
            0.10780376195907593,
            0.10732115060091019
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.3988153040409088,
            0.39719685912132263,
            0.3971548080444336,
            0.3945147395133972,
            0.3967544436454773
        ]
    },
    "learning_params": {
        "learning_rate": 3.665965528927109e-05,
        "projection_dim": 72,
        "num_heads": 6,
        "drop_out_1": 0.3416832007005135,
        "drop_out_2": 0.14887085198664124,
        "drop_out_3": 0.05599251173642324,
        "transformer_layers": 6,
        "patch_size": 16,
        "activation": "softmax",
        "weight": 0.0018107843722353601,
        "momentum": 5.408831163946477e-08,
        "optimizer": "AdamW"
    }
}

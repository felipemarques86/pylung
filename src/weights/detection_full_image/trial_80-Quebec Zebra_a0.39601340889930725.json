{
    "trial_id": "80",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.10904290527105331,
        0.39601340889930725
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.11333087831735611,
            0.11254525184631348,
            0.11239033937454224,
            0.1121012270450592,
            0.11221933364868164
        ],
        "bounding_box_intersection_over_union_tf": [
            0.38848552107810974,
            0.3897920548915863,
            0.3891068994998932,
            0.38943323493003845,
            0.38903558254241943
        ],
        "val_loss": [
            0.10930177569389343,
            0.10910803824663162,
            0.10906963795423508,
            0.10905712097883224,
            0.10904289782047272
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.39711615443229675,
            0.39678898453712463,
            0.39643025398254395,
            0.39608269929885864,
            0.3960132896900177
        ]
    },
    "learning_params": {
        "learning_rate": 0.000799869390705132,
        "projection_dim": 88,
        "num_heads": 2,
        "drop_out_1": 0.01228691612925257,
        "drop_out_2": 0.06107834728778213,
        "drop_out_3": 0.05026707932647693,
        "transformer_layers": 5,
        "patch_size": 32,
        "activation": "softmax",
        "weight": 5.775725161501838e-08,
        "momentum": 3.6898820941090056e-06,
        "optimizer": "SGD"
    }
}

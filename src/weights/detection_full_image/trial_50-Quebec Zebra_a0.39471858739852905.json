{
    "trial_id": "50",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.10869693756103516,
        0.39471858739852905
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.11015839874744415,
            0.10998699069023132,
            0.11018379777669907,
            0.11025295406579971,
            0.11049409955739975
        ],
        "bounding_box_intersection_over_union_tf": [
            0.3951042890548706,
            0.3943621516227722,
            0.39350706338882446,
            0.3929169774055481,
            0.3914695382118225
        ],
        "val_loss": [
            0.10772353410720825,
            0.10798495262861252,
            0.10819382220506668,
            0.10858350992202759,
            0.10869692265987396
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.3994540572166443,
            0.3966711163520813,
            0.3962610960006714,
            0.3923707902431488,
            0.3947184383869171
        ]
    },
    "learning_params": {
        "learning_rate": 4.0334018504381374e-05,
        "projection_dim": 116,
        "num_heads": 4,
        "drop_out_1": 0.3925131134569493,
        "drop_out_2": 0.01092281985074535,
        "drop_out_3": 0.03315505519995984,
        "transformer_layers": 5,
        "patch_size": 64,
        "activation": "softmax",
        "weight": 0.005026507879545484,
        "momentum": 4.232016498321456e-08,
        "optimizer": "AdamW"
    }
}

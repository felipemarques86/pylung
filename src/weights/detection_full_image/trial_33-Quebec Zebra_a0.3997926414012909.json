{
    "trial_id": "33",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.10599324107170105,
        0.3997926414012909
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.11145484447479248,
            0.11046683043241501,
            0.10967325419187546,
            0.10911700874567032,
            0.10879553109407425
        ],
        "bounding_box_intersection_over_union_tf": [
            0.39172327518463135,
            0.3942689895629883,
            0.39563360810279846,
            0.39608773589134216,
            0.39652544260025024
        ],
        "val_loss": [
            0.10822734236717224,
            0.10744614154100418,
            0.10646376758813858,
            0.10631164163351059,
            0.10599328577518463
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.3976649045944214,
            0.39945080876350403,
            0.4016439914703369,
            0.39945974946022034,
            0.39979246258735657
        ]
    },
    "learning_params": {
        "learning_rate": 9.377881830392365e-06,
        "projection_dim": 80,
        "num_heads": 6,
        "drop_out_1": 0.1859497626943147,
        "drop_out_2": 0.2609733173256708,
        "drop_out_3": 0.07573813138429134,
        "transformer_layers": 6,
        "patch_size": 32,
        "activation": "softmax",
        "weight": 5.201619123173054e-07,
        "momentum": 1.1584296897917042e-08,
        "optimizer": "AdamW"
    }
}

{
    "trial_id": "11",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 150,
    "epochs": 10,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Papa Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.28943246603012085,
        0.0
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.29069533944129944,
            0.29192858934402466,
            0.2920021414756775,
            0.2919106185436249,
            0.2919411063194275,
            0.2919987440109253,
            0.2920137643814087,
            0.29198768734931946,
            0.2919003963470459,
            0.2919895648956299
        ],
        "bounding_box_intersection_over_union_tf": [
            0.004621447063982487,
            0.00041050073923543096,
            0.00047766376519575715,
            0.00037507820525206625,
            0.0004121624515391886,
            0.0005496828234754503,
            0.0004264948656782508,
            0.00043022786849178374,
            0.0003179606865160167,
            0.00038353391573764384
        ],
        "val_loss": [
            0.28943246603012085,
            0.28943246603012085,
            0.28943246603012085,
            0.28943246603012085,
            0.28943246603012085,
            0.28943246603012085,
            0.28943246603012085,
            0.28943246603012085,
            0.28943246603012085,
            0.28943246603012085
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0,
            0.0
        ]
    },
    "learning_params": {
        "learning_rate": 0.053774961752856766,
        "projection_dim": 86,
        "num_heads": 2,
        "drop_out_1": 0.2998780302314639,
        "drop_out_2": 0.0709456064449862,
        "drop_out_3": 0.18378656171065705,
        "transformer_layers": 6,
        "patch_size": 16,
        "activation": "softmax",
        "weight": 0.0009357920675467482,
        "momentum": 2.89329531370808e-06,
        "optimizer": "AdamW"
    }
}

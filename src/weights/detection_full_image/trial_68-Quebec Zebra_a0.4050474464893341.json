{
    "trial_id": "68",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.10431337356567383,
        0.4050474464893341
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.11186852306127548,
            0.10959576815366745,
            0.10863552242517471,
            0.1080947071313858,
            0.10710150748491287
        ],
        "bounding_box_intersection_over_union_tf": [
            0.3900785744190216,
            0.39452067017555237,
            0.3961522579193115,
            0.3972170054912567,
            0.3986244797706604
        ],
        "val_loss": [
            0.10846265405416489,
            0.10694689303636551,
            0.10671041160821915,
            0.105235256254673,
            0.10431331396102905
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.3862438499927521,
            0.39280855655670166,
            0.39173752069473267,
            0.3988587260246277,
            0.4050479531288147
        ]
    },
    "learning_params": {
        "learning_rate": 0.00014605259323402799,
        "projection_dim": 82,
        "num_heads": 2,
        "drop_out_1": 0.17866282094583283,
        "drop_out_2": 0.13355488436652765,
        "drop_out_3": 0.11204592673628645,
        "transformer_layers": 6,
        "patch_size": 32,
        "activation": "softmax",
        "weight": 9.268137239415729e-08,
        "momentum": 3.105319324561223e-08,
        "optimizer": "AdamW"
    }
}

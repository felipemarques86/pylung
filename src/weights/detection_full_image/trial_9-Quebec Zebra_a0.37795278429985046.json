{
    "trial_id": "9",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.11110328137874603,
        0.37795278429985046
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.11548443883657455,
            0.11444049328565598,
            0.11375100165605545,
            0.11331210285425186,
            0.11308962106704712
        ],
        "bounding_box_intersection_over_union_tf": [
            0.37173959612846375,
            0.3740991950035095,
            0.37479284405708313,
            0.37563738226890564,
            0.37604212760925293
        ],
        "val_loss": [
            0.1117381826043129,
            0.1115226224064827,
            0.11135302484035492,
            0.11121541261672974,
            0.11110328137874603
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.3767492473125458,
            0.37711021304130554,
            0.37743520736694336,
            0.3777215778827667,
            0.37795254588127136
        ]
    },
    "learning_params": {
        "learning_rate": 5.079378676835228e-09,
        "projection_dim": 92,
        "num_heads": 4,
        "drop_out_1": 0.05730401749067026,
        "drop_out_2": 0.06698478457460784,
        "drop_out_3": 0.0674951534196163,
        "transformer_layers": 5,
        "patch_size": 16,
        "activation": "softmax",
        "weight": 0.00023944138393268934,
        "momentum": 0.00012836501428671696,
        "optimizer": "AdamW"
    }
}

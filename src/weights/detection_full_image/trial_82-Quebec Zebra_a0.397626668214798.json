{
    "trial_id": "82",
    "model_type": "vit",
    "image_size": 224,
    "batch_size": 200,
    "epochs": 5,
    "num_classes": 4,
    "loss": "mse",
    "code_name": "Quebec Zebra",
    "isolate_nodule_image": false,
    "detection": true,
    "static_params": false,
    "score": [
        0.10502421855926514,
        0.397626668214798
    ],
    "score_names": [
        "loss",
        "bounding_box_intersection_over_union_tf"
    ],
    "x_train_size": 15048,
    "y_train_size": 15048,
    "x_valid_size": 3135,
    "y_valid_size": 3135,
    "image_channels": 1,
    "version": 1,
    "data_transformer_name": "bbox",
    "history": {
        "loss": [
            0.11143549531698227,
            0.1096121072769165,
            0.10855729877948761,
            0.10781251639127731,
            0.10715863853693008
        ],
        "bounding_box_intersection_over_union_tf": [
            0.39025652408599854,
            0.39479517936706543,
            0.3963209390640259,
            0.39730292558670044,
            0.3983127176761627
        ],
        "val_loss": [
            0.10790225863456726,
            0.10598628968000412,
            0.10544988512992859,
            0.105270154774189,
            0.10502424836158752
        ],
        "val_bounding_box_intersection_over_union_tf": [
            0.3906882405281067,
            0.3995547592639923,
            0.40061864256858826,
            0.39774543046951294,
            0.3976265490055084
        ]
    },
    "learning_params": {
        "learning_rate": 0.00011080483822445253,
        "projection_dim": 82,
        "num_heads": 2,
        "drop_out_1": 0.28998096969095727,
        "drop_out_2": 0.16711471869319539,
        "drop_out_3": 0.16696772343546504,
        "transformer_layers": 5,
        "patch_size": 32,
        "activation": "softmax",
        "weight": 0.0003956085672769482,
        "momentum": 1.1719499552354242e-07,
        "optimizer": "AdamW"
    }
}
